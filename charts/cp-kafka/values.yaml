# Default values for cp-kafka.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

## ------------------------------------------------------
## Kafka
## ------------------------------------------------------

## Number of Kafka brokers
brokers: 3

## Image Info
## ref: https://hub.docker.com/r/confluentinc/cp-kafka/
image: confluentinc/cp-kafka
imageTag: 4.0.1

## Specify a imagePullPolicy
## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
imagePullPolicy: IfNotPresent

## Liveness and Readiness Probe Configuration
livenessProbe:
  initialDelaySeconds: 30
  timeoutSeconds: 5
readinessProbe:
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  successThreshold: 1
  failureThreshold: 3

## StatefulSet Config
## Start and stop pods in Parallel or OrderedReady (one-by-one.)
## ref: https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#pod-management-policy
podManagementPolicy: Parallel

## The StatefulSet Update Strategy which Kafka will use when changes are applied.
## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
updateStrategy: OnDelete

jmx:
  port: 5555
  configMap:
    enabled: true
    whitelistObjectNames:
      - kafka.controller:*
      - kafka.server:*
      - java.lang:*
      - kafka.network:*
      - kafka.log:*

prometheus:
  jmx:
    enabled: true
    image: solsson/kafka-prometheus-jmx-exporter@sha256
    imageTag: a23062396cd5af1acdf76512632c20ea6be76885dfc20cd9ff40fb23846557e8
    interval: 10s
    port: 5556

persistence:
  enabled: true

  ## The size of the PersistentVolume to allocate to each Kafka Pod in the StatefulSet. For
  ## production servers this number should likely be much larger.
  size: 1Gi

  ## Kafka data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass:

configurationOverrides:
  "offsets.topic.replication.factor": 3
  # "auto.leader.rebalance.enable": true
  # "auto.create.topics.enable": true
  # "controlled.shutdown.enable": true
  # "controlled.shutdown.max.retries": 100


#  "advertised.listeners": |-
#    PLAINTEXT://$(POD_IP):9092
#  "listener.security.protocol.map":
#    PLAINTEXT:PLAINTEXT
  ## Options required for external access via NodePort
  ## ref:
  ## - http://kafka.apache.org/documentation/#security_configbroker
  ## - https://cwiki.apache.org/confluence/display/KAFKA/KIP-103%3A+Separation+of+Internal+and+External+traffic
  ##
  ## Setting "advertised.listeners" here appends to "PLAINTEXT://${POD_IP}:9092,"
  "advertised.listeners": |-
   EXTERNAL://${HOST_IP}:$((31090 + ${KAFKA_BROKER_ID}))
  "listener.security.protocol.map": |-
   PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #  cpu: 100m
  #  memory: 128Mi
  # requests:
  #  cpu: 100m
  #  memory: 128Mi

## ------------------------------------------------------
## Zookeeper
## ------------------------------------------------------
cp_zookeeper:
  ## If true, install the cp-zookeeper chart alongside cp-kafka
  ## ref: ../cp-zookeeper
  enabled: true

  ## If the Zookeeper Chart is disabled a URL and port are required to connect
  url: ""
  clientPort: 2181

external:
  enabled: false
  servicePort: 19092
  firstListenerPort: 31090